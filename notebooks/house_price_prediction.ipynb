{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices: Advanced Regression Techniques\n",
    "\n",
    "This notebook covers the end-to-end process for the House Prices Kaggle competition.\n",
    "\n",
    "## Steps:\n",
    "1. **EDA**: Analyze target variable and missing values.\n",
    "2. **Feature Engineering**: Create new features and encode categoricals.\n",
    "3. **Modeling**: Train and evaluate Linear, Ridge, Lasso, Random Forest, and XGBoost.\n",
    "4. **Submission**: Generate `submission.csv` and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv('../data/train.csv')\n",
    "    test_df = pd.read_csv('../data/test.csv')\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(f\"Train shape: {train_df.shape}\")\n",
    "    print(f\"Test shape: {test_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Files not found. Please ensure 'train.csv' and 'test.csv' are in the 'data/' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_df' in locals():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(train_df['SalePrice'], kde=True)\n",
    "    plt.title('Distribution of SalePrice')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Skewness: %f\" % train_df['SalePrice'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_df' in locals():\n",
    "    missing = train_df.isnull().sum()\n",
    "    missing = missing[missing > 0].sort_values(ascending=False)\n",
    "    if not missing.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        missing.plot.bar()\n",
    "        plt.title('Missing Values by Feature')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # Handle Missing Values (Simple imputation for baseline)\n",
    "    # Categorical: Fill with 'None' or Mode\n",
    "    cat_cols = df_eng.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        df_eng[col] = df_eng[col].fillna('None')\n",
    "        \n",
    "    # Numerical: Fill with Median\n",
    "    num_cols = df_eng.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in num_cols:\n",
    "        df_eng[col] = df_eng[col].fillna(df_eng[col].median())\n",
    "    \n",
    "    # 1. Total Square Footage\n",
    "    # Using fillna(0) just in case, though we imputed above\n",
    "    df_eng['TotalSF'] = df_eng['TotalBsmtSF'] + df_eng['1stFlrSF'] + df_eng['2ndFlrSF']\n",
    "    \n",
    "    # 2. Total Porch Area\n",
    "    df_eng['TotalPorchSF'] = (df_eng['OpenPorchSF'] + df_eng['3SsnPorch'] +\n",
    "                              df_eng['EnclosedPorch'] + df_eng['ScreenPorch'] +\n",
    "                              df_eng['WoodDeckSF'])\n",
    "                              \n",
    "    # 3. House Age and Garage Age\n",
    "    # Ensure years are valid. If YearBuilt > YrSold (data error), set Age to 0\n",
    "    df_eng['HouseAge'] = df_eng['YrSold'] - df_eng['YearBuilt']\n",
    "    df_eng['HouseAge'] = df_eng['HouseAge'].apply(lambda x: max(0, x))\n",
    "    \n",
    "    # Handle GarageYrBlt missingness logic specifically if needed, but we imputed median above.\n",
    "    # A better approach for GarageYrBlt is usually to set it to YearBuilt if missing, \n",
    "    # but our generic median imputation covers it for a baseline script.\n",
    "    # Let's refine it slightly to be more logical if the column exists originaly with NaNs\n",
    "    if 'GarageYrBlt' in df.columns and df['GarageYrBlt'].isnull().any():\n",
    "         # Re-impute specifically: if no garage, use YearBuilt\n",
    "         df_eng['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['YearBuilt'])\n",
    "    \n",
    "    df_eng['GarageAge'] = df_eng['YrSold'] - df_eng['GarageYrBlt']\n",
    "    df_eng['GarageAge'] = df_eng['GarageAge'].apply(lambda x: max(0, x))\n",
    "    \n",
    "    return df_eng\n",
    "\n",
    "if 'train_df' in locals():\n",
    "    # Log Transform Target\n",
    "    train_df['SalePrice'] = np.log1p(train_df['SalePrice'])\n",
    "    \n",
    "    # Store Id for submission\n",
    "    test_ids = test_df['Id']\n",
    "    \n",
    "    # Drop Id column for training\n",
    "    train_df.drop('Id', axis=1, inplace=True)\n",
    "    test_df.drop('Id', axis=1, inplace=True)\n",
    "    \n",
    "    # Combine for consistent encoding\n",
    "    ntrain = train_df.shape[0]\n",
    "    ntest = test_df.shape[0]\n",
    "    y_train_full = train_df['SalePrice'].values\n",
    "    \n",
    "    all_data = pd.concat((train_df.drop('SalePrice', axis=1), test_df)).reset_index(drop=True)\n",
    "    \n",
    "    # Apply Feature Engineering\n",
    "    all_data = feature_engineering(all_data)\n",
    "    \n",
    "    # One-Hot Encoding\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    \n",
    "    # Split back\n",
    "    X_train_full = all_data[:ntrain]\n",
    "    X_test_full = all_data[ntrain:]\n",
    "    \n",
    "    print(\"Feature Engineering Complete.\")\n",
    "    print(f\"New shape: {X_train_full.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train_full' in locals():\n",
    "    # Split for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Preprocessing (Scaling) - important for Linear/Ridge/Lasso\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.001),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, n_jobs=-1)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"Model Evaluation (RMSE on Log Prices):\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    best_model_name = \"\"\n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if name in ['Linear Regression', 'Ridge', 'Lasso']:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            preds = model.predict(X_val_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            \n",
    "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        results[name] = rmse\n",
    "        print(f\"{name}: {rmse:.4f}\")\n",
    "        \n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model_name = name\n",
    "            \n",
    "    print(\"-\"*40)\n",
    "    print(f\"Best Model: {best_model_name} with RMSE: {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train on Full Data and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'best_model_name' in locals():\n",
    "    final_model = models[best_model_name]\n",
    "    \n",
    "    print(f\"Retraining {best_model_name} on full dataset...\")\n",
    "    \n",
    "    # Scaling for linear models check\n",
    "    if best_model_name in ['Linear Regression', 'Ridge', 'Lasso']:\n",
    "        scaler_full = StandardScaler()\n",
    "        X_train_final = scaler_full.fit_transform(X_train_full)\n",
    "        X_test_final = scaler_full.transform(X_test_full)\n",
    "        final_model.fit(X_train_final, y_train_full)\n",
    "        final_predictions_log = final_model.predict(X_test_final)\n",
    "    else:\n",
    "        final_model.fit(X_train_full, y_train_full)\n",
    "        final_predictions_log = final_model.predict(X_test_full)\n",
    "        \n",
    "    # Inverse transform (exp) to get actual prices\n",
    "    final_predictions = np.expm1(final_predictions_log)\n",
    "    \n",
    "    # Submission CSV\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': test_ids,\n",
    "        'SalePrice': final_predictions\n",
    "    })\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    import os\n",
    "    if not os.path.exists('../outputs'):\n",
    "        os.makedirs('../outputs')\n",
    "    \n",
    "    submission_path = '../outputs/submission.csv'\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"Submission saved to {submission_path}\")\n",
    "    \n",
    "    # Save Model\n",
    "    if not os.path.exists('../models'):\n",
    "        os.makedirs('../models')\n",
    "        \n",
    "    model_path = '../models/model.pkl'\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(final_model, f)\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
